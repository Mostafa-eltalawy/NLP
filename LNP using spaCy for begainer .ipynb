{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'counter' from 'collections' (C:\\Users\\Mostafa Eltalawy\\anaconda3\\lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2f43c83218f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'counter' from 'collections' (C:\\Users\\Mostafa Eltalawy\\anaconda3\\lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#importing lib\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "from collections import counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Trump claims that he had no choice but to risk his own health. Americans disagree. and Infectious Trump briefly leaves hospital to greet supporters. also  Positive tests for senators raise doubts about fast-track confirmation of Trump’s Supreme Court choice'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading text \n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump claims that he had no choice but to risk his own health.\n",
      "Americans disagree.\n",
      "and Infectious Trump briefly leaves hospital to greet supporters.\n",
      "also  Positive tests for senators raise doubts about fast-track confirmation of Trump’s Supreme Court choice\n"
     ]
    }
   ],
   "source": [
    "#making sentances tokenzation ...coverting text to seperate sentances \n",
    "for sentances in doc.sents:\n",
    "    print(sentances)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump', 'claims', 'that', 'he', 'had', 'no', 'choice', 'but', 'to', 'risk', 'his', 'own', 'health', '.', 'Americans', 'disagree', '.', 'and', 'Infectious', 'Trump', 'briefly', 'leaves', 'hospital', 'to', 'greet', 'supporters', '.', 'also', ' ', 'Positive', 'tests', 'for', 'senators', 'raise', 'doubts', 'about', 'fast', '-', 'track', 'confirmation', 'of', 'Trump', '’s', 'Supreme', 'Court', 'choice']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making tokenization for words .. converting text to words     \n",
    "tok_words=[]\n",
    "for word in doc:\n",
    "    tok_words.append(word.text)\n",
    "    \n",
    "print(tok_words)\n",
    "len(tok_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'herself', 'else', 'thus', 'could', 'less', 'hence', 'although', 'below', 'herein', 'did', 'doing', 'must', 'into', 'still', \"'ve\", 'them', 'throughout', 'i', 'these', 'using', 'few', 'now', 'yourself', 'myself', 'twelve', 'next', 'him', 'various', 'front', 'often', 'meanwhile', 'during', 'this', 'for', 'seeming', 'hundred', 'latterly', 'does', 'from', 'make', 'third', 'almost', \"n't\", 'rather', 'get', 'the', 'anywhere', 'we', 'whatever', 'all', 'again', 'she', 'hereupon', 'in', 'becoming', 'thereupon', 'around', 'becomes', 'onto', 'due', 'several', 'noone', 'therefore', 'your', 'you', 'because', 'while', 'alone', 'hers', 'two', 'fifty', 'can', 'also', 'beforehand', 'full', 'sixty', 'except', 'further', 'toward', 'please', 'here', 'seem', 'really', 'just', 'are', 'though', 'me', 'quite', 'last', 'he', '‘re', 'enough', 'whence', '’re', 'however', 'became', 'ca', 'will', 'why', 'only', 'sometimes', '‘ve', 'always', 'beyond', 'other', 'but', \"'d\", 'by', 'eleven', 'whereupon', 'very', 'whole', 'too', 'was', 'well', 'move', 'none', 'among', 'his', 'no', 'many', 'it', 'any', 'or', 'upon', 'much', 'back', 'its', 'n’t', 'same', 'more', 'over', 'thereby', 'take', 'until', 'part', 'anyway', 'say', 'up', '’d', 'since', 'how', 'three', 'five', 'be', 'they', 'and', 'some', 'top', 'ever', 'not', 'have', 'of', 'see', 'empty', 'regarding', 'others', 'whom', 'amongst', 'never', 'everywhere', 'give', 'whoever', 'my', 'thru', 'mine', 'neither', 'us', 'used', 'may', 'first', 'otherwise', 'had', 'so', 'hereby', 'anything', 'via', 'might', 'yourselves', 'being', \"'m\", 'anyhow', 'across', 'seemed', 'above', 'a', 'show', 'least', 'whose', 'that', 'wherever', 'eight', 'about', '’ll', 'whither', 'thence', 'already', 'at', 'her', 'themselves', 'something', 'our', 'those', 'beside', '’ve', 'every', 'name', 'where', 'thereafter', 'keep', 'before', 'each', \"'ll\", 'yours', 'nevertheless', 'there', 'twenty', 're', 'against', 'whereby', 'serious', 'than', 'both', 'within', 'moreover', 'himself', 'towards', 'afterwards', 'as', 'who', 'an', 'out', 'should', 'somewhere', '‘m', 'then', 'such', '’m', 'off', 'latter', 'someone', '‘ll', 'itself', 'down', 'former', 'everything', 'would', 'done', 'without', 'along', 'six', 'become', 'go', 'forty', 'when', 'seems', 'another', 'four', 'besides', \"'s\", 'nine', 'do', 'call', 'one', 'anyone', 'sometime', 'perhaps', 'their', '’s', 'everyone', 'together', 'made', 'ours', 'is', 'namely', 'whether', 'were', 'either', 'ourselves', 'nor', 'own', 'indeed', 'nowhere', 'wherein', 'ten', 'amount', 'which', 'unless', 'am', 'behind', 'whereas', 'nobody', 'therein', 'once', 'has', 'per', \"'re\", 'with', 'somehow', 'if', 'n‘t', 'mostly', 'to', 'between', '‘s', 'after', 'cannot', 'side', 'on', 'yet', 'what', 'formerly', 'whenever', 'elsewhere', 'most', 'under', 'even', 'been', 'through', 'whereafter', 'nothing', '‘d', 'fifteen', 'hereafter', 'put', 'bottom'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check stop words \n",
    "StopWords=spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(StopWords)\n",
    "len(StopWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump', 'claims', 'choice', 'risk', 'health', '.', 'Americans', 'disagree', '.', 'Infectious', 'Trump', 'briefly', 'leaves', 'hospital', 'greet', 'supporters', '.', ' ', 'Positive', 'tests', 'senators', 'raise', 'doubts', 'fast', '-', 'track', 'confirmation', 'Trump', 'Supreme', 'Court', 'choice']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stop words as it is not important \n",
    "filtered_words=[]\n",
    "\n",
    "for w in tok_words:\n",
    "    if w not in StopWords:\n",
    "        filtered_words.append(w)\n",
    "        \n",
    "print(filtered_words)\n",
    "len(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Trump', 'ADJ', 'JJ')\n",
      "('claims', 'NOUN', 'NNS')\n",
      "('that', 'SCONJ', 'IN')\n",
      "('he', 'PRON', 'PRP')\n",
      "('had', 'AUX', 'VBD')\n",
      "('no', 'DET', 'DT')\n",
      "('choice', 'NOUN', 'NN')\n",
      "('but', 'SCONJ', 'IN')\n",
      "('to', 'PART', 'TO')\n",
      "('risk', 'VERB', 'VB')\n",
      "('his', 'DET', 'PRP$')\n",
      "('own', 'ADJ', 'JJ')\n",
      "('health', 'NOUN', 'NN')\n",
      "('.', 'PUNCT', '.')\n",
      "('Americans', 'PROPN', 'NNPS')\n",
      "('disagree', 'VERB', 'VBP')\n",
      "('.', 'PUNCT', '.')\n",
      "('and', 'CCONJ', 'CC')\n",
      "('Infectious', 'PROPN', 'NNP')\n",
      "('Trump', 'PROPN', 'NNP')\n",
      "('briefly', 'ADV', 'RB')\n",
      "('leaves', 'VERB', 'VBZ')\n",
      "('hospital', 'NOUN', 'NN')\n",
      "('to', 'PART', 'TO')\n",
      "('greet', 'VERB', 'VB')\n",
      "('supporters', 'NOUN', 'NNS')\n",
      "('.', 'PUNCT', '.')\n",
      "('also', 'ADV', 'RB')\n",
      "(' ', 'SPACE', '_SP')\n",
      "('Positive', 'ADJ', 'JJ')\n",
      "('tests', 'NOUN', 'NNS')\n",
      "('for', 'ADP', 'IN')\n",
      "('senators', 'NOUN', 'NNS')\n",
      "('raise', 'VERB', 'VBP')\n",
      "('doubts', 'NOUN', 'NNS')\n",
      "('about', 'ADP', 'IN')\n",
      "('fast', 'ADJ', 'JJ')\n",
      "('-', 'PUNCT', 'HYPH')\n",
      "('track', 'NOUN', 'NN')\n",
      "('confirmation', 'NOUN', 'NN')\n",
      "('of', 'ADP', 'IN')\n",
      "('Trump', 'PROPN', 'NNP')\n",
      "('’s', 'PART', 'POS')\n",
      "('Supreme', 'PROPN', 'NNP')\n",
      "('Court', 'PROPN', 'NNP')\n",
      "('choice', 'NOUN', 'NN')\n"
     ]
    }
   ],
   "source": [
    "#checking tag and pos\n",
    "\n",
    "for token in doc:\n",
    "    print((token.text,token.pos_,token.tag_))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump claims\n",
      "he\n",
      "no choice\n",
      "his own health\n",
      "Americans\n",
      "Infectious Trump\n",
      "hospital\n",
      "supporters\n",
      "Positive tests\n",
      "senators\n",
      "doubts\n",
      "fast-track confirmation\n",
      "Trump\n"
     ]
    }
   ],
   "source": [
    "#detecting Nouns\n",
    "\n",
    "for Noun in doc.noun_chunks:\n",
    "    print(Noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Americans NORP\n",
      "Infectious Trump ORG\n",
      "Positive ORG\n",
      "Trump ORG\n",
      "Supreme Court ORG\n"
     ]
    }
   ],
   "source": [
    "#NER\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Trump claims that he had no choice but to risk his own health. \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Americans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " disagree. and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Infectious Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " briefly leaves hospital to greet supporters. also  \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Positive\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " tests for senators raise doubts about fast-track confirmation of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Supreme Court\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " choice</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in doc.ents:\n",
    "    (i,i.label_,i.label)\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump --> nsubj\n",
      "claims --> ROOT\n",
      "that --> mark\n",
      "he --> nsubj\n",
      "had --> ccomp\n",
      "no --> det\n",
      "choice --> dobj\n",
      "but --> prep\n",
      "to --> aux\n",
      "risk --> pcomp\n",
      "his --> poss\n",
      "own --> amod\n",
      "health --> dobj\n",
      ". --> punct\n",
      "Americans --> nsubj\n",
      "disagree --> ROOT\n",
      ". --> punct\n",
      "and --> cc\n",
      "Infectious --> compound\n",
      "Trump --> nsubj\n",
      "briefly --> advmod\n",
      "leaves --> ROOT\n",
      "hospital --> dobj\n",
      "to --> aux\n",
      "greet --> advcl\n",
      "supporters --> dobj\n",
      ". --> punct\n",
      "also --> advmod\n",
      "  --> \n",
      "Positive --> amod\n",
      "tests --> nsubj\n",
      "for --> prep\n",
      "senators --> pobj\n",
      "raise --> ROOT\n",
      "doubts --> dobj\n",
      "about --> prep\n",
      "fast --> amod\n",
      "- --> punct\n",
      "track --> compound\n",
      "confirmation --> pobj\n",
      "of --> prep\n",
      "Trump --> pobj\n",
      "’s --> punct\n",
      "Supreme --> compound\n",
      "Court --> compound\n",
      "choice --> npadvmod\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"-->\", token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nominal subject',\n",
       " None,\n",
       " 'auxiliary',\n",
       " 'adverbial clause modifier',\n",
       " 'direct object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"nsubj\"), spacy.explain(\"ROOT\"), spacy.explain(\"aux\"), spacy.explain(\"advcl\"), spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Import spaCy Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Initialize the matcher with the spaCy vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\"Some people start their day with lemon water\")\n",
    "\n",
    "# Define rule\n",
    "pattern = [{'TEXT': 'lemon'}, {'TEXT': 'water'}]\n",
    "\n",
    "# Add rule\n",
    "matcher.add('rule_1', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7604275899133490726, 6, 8)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemon water\n"
     ]
    }
   ],
   "source": [
    "# Extract matched text\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
